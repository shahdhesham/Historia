{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=\"C:/Users/20112/onedrive/Desktop/keras-video-classification/keras-video-classification/data\"\n",
    "outputlabelbinarizer=\"C:/Users/20112/Desktop/keras-video-classification/keras-video-classification/model/videoclassificationbinarizer\"\n",
    "outputmodel=\"C:/Users/20112/Desktop/keras-video-classification/keras-video-classification/output/videoclassificationmodel\"\n",
    "epoch=5\n",
    "LABELS = set([ \"qutub_minar\",\"alai_darwaza\",\"iron_pillar\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\t# if the label of the current image is not part of of the labels\n",
    "\t# are interested in, then ignore the image\n",
    "\tif label not in LABELS:\n",
    "\t\tcontinue\n",
    "\n",
    "\t# load the image, convert it to RGB channel ordering, and resize\n",
    "\t# it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (128, 128))\n",
    "\t# image = cv2.resize(image, (28, 28))\n",
    "\t# image = img_to_array(image)\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, stratify=labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "\n",
    "X_test = X_test / 255.0\n",
    "X_test = tf.cast(X_test, dtype=tf.float32)\n",
    "X_test = tf.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_16 (Dense)             (None, 50)                39250     \n_________________________________________________________________\ndense_17 (Dense)             (None, 10)                510       \n=================================================================\nTotal params: 39,760\nTrainable params: 39,760\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_num_units = 784\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# create model\n",
    "model = Sequential([\n",
    " Dense(units=hidden_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dense(units=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile the model with necessary attributes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 1)\n",
    "\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "batch_size = 128\n",
    "pool_size = (2,2)\n",
    "model = Sequential([\n",
    "#  InputLayer(input_shape=input_reshape),\n",
    "\n",
    "Conv2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "Conv2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "Conv2D(25, 4, 4, activation='relu'),\n",
    "\n",
    "Flatten(),\n",
    "\n",
    "Dense(units=hidden_num_units, activation='relu'),\n",
    "\n",
    "Dense(units=output_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.build(input_shape)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, n_class, routings):\n",
    "   x = layers.Input(shape=input_shape)\n",
    "\n",
    "   # Layer 1: Just a conventional Conv2D layer\n",
    "   conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "   # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "   primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "   # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "   digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "   name='digitcaps')(primarycaps)\n",
    "\n",
    "   # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "   # If using tensorflow, this will not be necessary. :)\n",
    "   out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "   # Decoder network.\n",
    "   y = layers.Input(shape=(n_class,))\n",
    "   masked_by_y = Mask()([digitcaps, y]) # The true label is used to mask the output of capsule layer. For training\n",
    "   masked = Mask()(digitcaps) # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "   # Shared Decoder model in training and prediction\n",
    "   decoder = models.Sequential(name='decoder')\n",
    "   decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "   decoder.add(layers.Dense(1024, activation='relu'))\n",
    "   decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "   decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "   # Models for training and evaluation (prediction)\n",
    "   train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "   eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "   # manipulate model\n",
    "   noise = layers.Input(shape=(n_class, 16))\n",
    "   noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "   masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "   manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "\n",
    "   return train_model, eval_model, manipulate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
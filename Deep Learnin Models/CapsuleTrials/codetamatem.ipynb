{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPeOS_Dk0B_M"
   },
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzmgIh5m0NW6"
   },
   "source": [
    "!pip uninstall keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1580161786933,
     "user": {
      "displayName": "lobna abo elmagd",
      "photoUrl": "",
      "userId": "03446022608341360913"
     },
     "user_tz": -120
    },
    "id": "GdlI0SPP0TKu",
    "outputId": "dd7ff9c9-628f-45d3-b133-0e92f395923b"
   },
   "source": [
    "!pip install keras==2.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXBCSfKC15Zk"
   },
   "source": [
    "pip install PyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtazA9W92Zgn"
   },
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssl86jq23Exn"
   },
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIW8VC963bO2"
   },
   "source": [
    " download = drive.CreateFile({'id':'1riOAwaOi6-eXdIrRYb2iqRcN5P8a4qdZ'})\n",
    "download.GetContentFile('tomato.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQJWmW1t4Tww"
   },
   "source": [
    "import zipfile\n",
    "import io\n",
    "data = zipfile.ZipFile('tomato.zip', 'r')\n",
    "data.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SS7P_TVAJn1z"
   },
   "outputs": [],
   "source": [
    "test_dir =\"D:/Graduation Project/dataset\"\n",
    "train_dir = \"D:/Graduation Project/dataset\"\n",
    "valid_dir='appledata/validate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiWLaYB340Ei"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";  # The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  # Do other imports now...\n",
    "from tensorflow.keras import layers,optimizers\n",
    "from tensorflow.keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer,Input\n",
    "from tensorflow.keras.layers import Reshape,MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obnctfs75MkT"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=30,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 shear_range=0.1,\n",
    "                                 horizontal_flip=True,\n",
    "                                 zoom_range=0.3,\n",
    "                                fill_mode='nearest')\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJEVi-GP5jVw"
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "if True:\n",
    "        save_to_dir=None\n",
    "else:\n",
    "        save_to_dir='augmented_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3038,
     "status": "ok",
     "timestamp": 1580151639853,
     "user": {
      "displayName": "lobna abo elmagd",
      "photoUrl": "",
      "userId": "03446022608341360913"
     },
     "user_tz": -120
    },
    "id": "25pLS_tq5vKG",
    "outputId": "b41fcd74-a3d6-4805-af8a-fbc201c5309e"
   },
   "outputs": [],
   "source": [
    "train_generator=train_datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size=(128,128),\n",
    "                                                  batch_size=batch_size,shuffle=True, save_to_dir=save_to_dir)\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(128,128),\n",
    "                                                  batch_size=batch_size,shuffle=False,\n",
    "                                                  save_to_dir=save_to_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4072,
     "status": "ok",
     "timestamp": 1580151650853,
     "user": {
      "displayName": "lobna abo elmagd",
      "photoUrl": "",
      "userId": "03446022608341360913"
     },
     "user_tz": -120
    },
    "id": "f8CmgPZcK7Ep",
    "outputId": "038c9233-9e4b-4205-bbea-90924c3051a1"
   },
   "source": [
    "!pip install h5py scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3177515,
     "status": "ok",
     "timestamp": 1580159218565,
     "user": {
      "displayName": "lobna abo elmagd",
      "photoUrl": "",
      "userId": "03446022608341360913"
     },
     "user_tz": -120
    },
    "id": "RM0MfTga2Gr-",
    "outputId": "9e7818a1-efd0-4114-890f-033fa44d94f7"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import utils\n",
    "#from keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# the squashing function.\n",
    "# we use 0.5 in stead of 1 in hinton's paper.\n",
    "# if 1, the norm of vector will be zoomed out.\n",
    "# if 0.5, the norm will be zoomed in while original norm is less than 0.5\n",
    "# and be zoomed out while original norm is greater than 0.5.\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x\n",
    "\n",
    "\n",
    "# define our own softmax function instead of K.softmax\n",
    "# because K.softmax can not specify axis.\n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "# define the margin loss like hinge loss\n",
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1\n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
    "\n",
    "\n",
    "class Capsule(Layer):\n",
    "    \"\"\"A Capsule Implement with Pure Keras\n",
    "    There are two vesions of Capsule.\n",
    "    One is like dense layer (for the fixed-shape input),\n",
    "    and the other is like timedistributed dense (for various length input).\n",
    "\n",
    "    The input shape of Capsule must be (batch_size,\n",
    "                                        input_num_capsule,\n",
    "                                        input_dim_capsule\n",
    "                                       )\n",
    "    and the output shape is (batch_size,\n",
    "                             num_capsule,\n",
    "                             dim_capsule\n",
    "                            )\n",
    "\n",
    "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
    "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_capsule,\n",
    "                 dim_capsule,\n",
    "                 routings=3,\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
    "        but replace b = b + <u,v> with b = <u,v>.\n",
    "        This change can improve the feature representation of Capsule.\n",
    "        However, you can replace\n",
    "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        with\n",
    "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        to realize a standard routing.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "\n",
    "\n",
    "batch_size = 32 #128\n",
    "num_classes = 3\n",
    "epochs = 5\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "#y_train = utils.to_categorical(y_train, num_classes)\n",
    "#y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# A common Conv2D model\n",
    "input_image = Input(shape=(128, 128, 3))\n",
    "x = Conv2D(64, (3, 3), activation='relu')(input_image)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x=Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(168, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(168, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(168, (3, 3), activation='relu')(x)\n",
    "x=Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "\n",
    "x=Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x=Flatten()(x)\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dense(512,activation='relu')(x)\n",
    "# newwwwwwwwwwwwwwww\n",
    "x=Dense(3,activation='softmax')(x)\n",
    "\n",
    "\"\"\"now we reshape it as (batch_size, input_num_capsule, input_dim_capsule)\n",
    "then connect a Capsule layer.\n",
    "\n",
    "the output of final model is the lengths of 10 Capsule, whose dim=16.\n",
    "\n",
    "the length of Capsule is the proba,\n",
    "so the problem becomes a 10 two-classification problem.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "x = Reshape((-1, 128))(x)\n",
    "capsule = Capsule(10, 16, 5, True)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "\"\"\"\n",
    "model = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "model.summary()\n",
    "checkpointer = ModelCheckpoint(filepath='TOMATOwithoutCOYt.weights.best.hdf5',monitor='val_loss', verbose = 1, save_best_only=True)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "# we use a margin loss\n",
    "#model.compile(loss=margin_loss, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-05),\n",
    "                 loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    " \n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                                  epochs=epochs,steps_per_epoch=20,\n",
    "                                  validation_data=test_generator,\n",
    "                                   verbose=1,callbacks=[checkpointer,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kll1j3r-1T3"
   },
   "outputs": [],
   "source": [
    "result = model.evaluate_generator(test_generator, steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1580159850322,
     "user": {
      "displayName": "lobna abo elmagd",
      "photoUrl": "",
      "userId": "03446022608341360913"
     },
     "user_tz": -120
    },
    "id": "Hxli8r5-_END",
    "outputId": "0449ce0a-9db2-409d-96ab-828419228f3c"
   },
   "outputs": [],
   "source": [
    "print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cr5aqp6l_mDD"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    # Get the classification accuracy and loss-value\n",
    "    # for the training-set.\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "\n",
    "    # Get it for the validation-set (we only use the test-set).\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    # Plot the accuracy and loss-values for the training-set.\n",
    "    plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n",
    "    plt.plot(loss, 'o', color='b', label='Training Loss')\n",
    "    \n",
    "    # Plot it for the test-set.\n",
    "    plt.plot(val_acc, linestyle='--', color='r', label='Test Acc.')\n",
    "    plt.plot(val_loss, 'o', color='r', label='Test Loss')\n",
    "\n",
    "    # Plot title and legend.\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Ensure the plot shows correctly.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1580159909190,
     "user": {
      "displayName": "lobna abo elmagd",
      "photoUrl": "",
      "userId": "03446022608341360913"
     },
     "user_tz": -120
    },
    "id": "ErOvguqf_ylO",
    "outputId": "8f95cc73-89fb-421e-b128-d0418fcd14d7"
   },
   "outputs": [],
   "source": [
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of capstomato",
   "provenance": [
    {
     "file_id": "13smFH3uKUwjZFmLlv7MiT_oFd3cLPlb6",
     "timestamp": 1580161525636
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

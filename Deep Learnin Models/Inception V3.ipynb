{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=\"C:/Users/20112/Desktop/keras-video-classification/keras-video-classification/data\"\n",
    "outputlabelbinarizer=\"C:/Users/20112/Desktop/keras-video-classification/keras-video-classification/model/videoclassificationbinarizer\"\n",
    "outputmodel=\"C:/Users/20112/Desktop/keras-video-classification/keras-video-classification/output/videoclassificationmodel\"\n",
    "epoch=25\n",
    "# initialize the set of labels from the spots activity dataset we are\n",
    "# going to train our network on\n",
    "LABELS = set([\"iron_pillar\", \"qutub_minar\",\"alai_darwaza\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\t# if the label of the current image is not part of of the labels\n",
    "\t# are interested in, then ignore the image\n",
    "\tif label not in LABELS:\n",
    "\t\tcontinue\n",
    "\n",
    "\t# load the image, convert it to RGB channel ordering, and resize\n",
    "\t# it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, stratify=labels, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=30,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
    "# Do note that the input image format for this model is different than for the VGG16 and ResNet models (299x299 instead of 224x224)\n",
    "# baseModel = InceptionV3(weights=\"imagenet\", include_top=False,\n",
    "# \tinput_tensor=Input(shape=(299, 299, 3)))\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "# baseModel = InceptionV3(input_shape = (150, 150, 3), include_top = False, weights = 'imagenet')\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "# headModel = baseModel.output\n",
    "# # headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "# # headModel = Flatten(name=\"flatten\")(headModel)\n",
    "# # headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "# # headModel = Dropout(0.5)(headModel)\n",
    "# # headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "# # from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# headModel =Flatten()(baseModel.output)\n",
    "# headModel = Dense(1024, activation='relu')(headModel)\n",
    "# headModel = Dropout(0.2)(headModel)\n",
    "# headModel = Dense(1, activation='sigmoid')(headModel)\n",
    "\n",
    "# # place the head FC model on top of the base model (this will become\n",
    "# # the actual model we will train)\n",
    "# # model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# model = Model(baseModel.input, headModel)\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable)\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / epoch)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({1: 219})"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(testY.argmax(axis=1))\n",
    "Counter(predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/25\n",
      "20/20 [==============================] - 89s 4s/step - loss: 140.9065 - accuracy: 0.3965 - val_loss: 0.9554 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 87s 4s/step - loss: 1.1346 - accuracy: 0.4205 - val_loss: 0.9486 - val_accuracy: 0.4375\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 87s 4s/step - loss: 1.0932 - accuracy: 0.4141 - val_loss: 1.1010 - val_accuracy: 0.4167\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 86s 4s/step - loss: 1.0766 - accuracy: 0.4141 - val_loss: 1.0510 - val_accuracy: 0.4635\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 87s 4s/step - loss: 1.0579 - accuracy: 0.4398 - val_loss: 1.0072 - val_accuracy: 0.4115\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 88s 4s/step - loss: 1.0426 - accuracy: 0.4414 - val_loss: 0.9626 - val_accuracy: 0.5417\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 88s 4s/step - loss: 1.0073 - accuracy: 0.5088 - val_loss: 0.9636 - val_accuracy: 0.6146\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 86s 4s/step - loss: 1.0704 - accuracy: 0.4639 - val_loss: 1.0881 - val_accuracy: 0.4271\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 82s 4s/step - loss: 1.0957 - accuracy: 0.4318 - val_loss: 1.0935 - val_accuracy: 0.4323\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 83s 4s/step - loss: 1.0923 - accuracy: 0.4398 - val_loss: 1.0898 - val_accuracy: 0.4427\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 82s 4s/step - loss: 1.0916 - accuracy: 0.4334 - val_loss: 1.0903 - val_accuracy: 0.4323\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 82s 4s/step - loss: 1.0887 - accuracy: 0.4446 - val_loss: 1.0895 - val_accuracy: 0.4531\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0898 - accuracy: 0.4302 - val_loss: 1.0885 - val_accuracy: 0.4427\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0888 - accuracy: 0.4334 - val_loss: 1.0879 - val_accuracy: 0.4115\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 80s 4s/step - loss: 1.0959 - accuracy: 0.4270 - val_loss: 1.0852 - val_accuracy: 0.4375\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 82s 4s/step - loss: 1.0865 - accuracy: 0.4350 - val_loss: 1.0863 - val_accuracy: 0.4479\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0821 - accuracy: 0.4398 - val_loss: 1.0851 - val_accuracy: 0.4323\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 82s 4s/step - loss: 1.0841 - accuracy: 0.4366 - val_loss: 1.0830 - val_accuracy: 0.4427\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0842 - accuracy: 0.4334 - val_loss: 1.0813 - val_accuracy: 0.4115\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0839 - accuracy: 0.4430 - val_loss: 1.0805 - val_accuracy: 0.4219\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0820 - accuracy: 0.4414 - val_loss: 1.0821 - val_accuracy: 0.4219\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0813 - accuracy: 0.4366 - val_loss: 1.0796 - val_accuracy: 0.4375\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0801 - accuracy: 0.4350 - val_loss: 1.0803 - val_accuracy: 0.4271\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 80s 4s/step - loss: 1.0727 - accuracy: 0.4398 - val_loss: 1.0800 - val_accuracy: 0.4375\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.0784 - accuracy: 0.4382 - val_loss: 1.0791 - val_accuracy: 0.4427\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "# train_generator=trainAug.flow(trainX, trainY, batch_size=32)\n",
    "H = model.fit(\n",
    "x=trainAug.flow(trainX, trainY, batch_size=32),\n",
    "\tsteps_per_epoch=len(trainX) // 32,\n",
    "\tvalidation_data=valAug.flow(testX, testY),\n",
    "\tvalidation_steps=len(testX) // 32,\n",
    "\tepochs=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX.astype(\"float32\"), batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\nalai_darwaza   0.000000  0.000000  0.000000        31\n iron_pillar   0.438356  1.000000  0.609524        96\n qutub_minar   0.000000  0.000000  0.000000        92\n\n    accuracy                       0.438356       219\n   macro avg   0.146119  0.333333  0.203175       219\nweighted avg   0.192156  0.438356  0.267189       219\n\n[0 1 1 0 1 1 2 1 2 1 0 0 1 1 0 2 2 2 1 1 2 2 1 0 1 2 2 2 1 1 2 2 1 2 2 2 1\n 2 0 1 2 2 1 2 2 0 2 1 1 1 2 1 2 1 1 2 1 0 2 0 0 1 1 1 1 1 1 0 2 0 1 2 2 1\n 2 1 2 2 2 1 1 1 0 1 1 0 2 2 0 0 2 1 2 2 0 0 0 2 2 1 1 0 1 2 1 1 1 0 2 0 2\n 1 1 1 2 1 1 2 1 1 0 2 2 2 2 2 1 2 1 2 1 1 2 1 2 1 1 2 2 2 1 2 2 1 1 2 2 2\n 1 1 2 1 0 1 1 0 2 1 2 1 2 2 1 2 2 2 1 0 1 2 0 1 1 2 2 0 1 2 2 1 2 2 1 2 1\n 1 2 2 1 1 1 2 2 2 2 1 2 1 0 1 2 1 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "\ttestY.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_, digits = 6))\n",
    "print(testY.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({1: 219})"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(testY.argmax(axis=1))\n",
    "Counter(predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot( H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot( H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Accuracy Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#y_score = model.predict(testX)\n",
    "y_score=predictions\n",
    "n_classes=3\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(testY[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(testY.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ]
}